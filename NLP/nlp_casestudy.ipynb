{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-casestudy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6nPEWhFbph6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15bf5af5-bd13-41fe-9265-3e163e3386e3"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"divyarathi31\"\n",
        "os.environ['KAGGLE_KEY'] = \"814901b6ab29e003e55b0dbb726e0c52\"\n",
        "!kaggle datasets download -d praveengovi/emotions-dataset-for-nlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading emotions-dataset-for-nlp.zip to /content\n",
            "\r  0% 0.00/721k [00:00<?, ?B/s]\n",
            "\r100% 721k/721k [00:00<00:00, 49.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_UU0fYTdMLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "123ef618-a7f5-46e5-b233-118b46b5f04c"
      },
      "source": [
        "!unzip \"/content/emotions-dataset-for-nlp.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/emotions-dataset-for-nlp.zip\n",
            "  inflating: test.txt                \n",
            "  inflating: train.txt               \n",
            "  inflating: val.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDhAVwchcq1k"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jZHA9SwdLn5"
      },
      "source": [
        "test = pd.read_csv('/content/test.txt',sep=\";\",header=None)\n",
        "train = pd.read_csv('/content/train.txt',sep=\";\",header=None)\n",
        "val = pd.read_csv('/content/val.txt',sep=\";\",header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHZpnXuXdl4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "53f57cf2-875d-4800-8217-20aa39bd8219"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im updating my blog because i feel shitty</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i never make her separate from me because i do...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i was feeling a little vain when i did this one</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0        1\n",
              "0  im feeling rather rotten so im not very ambiti...  sadness\n",
              "1          im updating my blog because i feel shitty  sadness\n",
              "2  i never make her separate from me because i do...  sadness\n",
              "3  i left with my bouquet of red and yellow tulip...      joy\n",
              "4    i was feeling a little vain when i did this one  sadness"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSQVBxC-do0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "5e4b694f-867d-485d-da30-bb08f2a8f79b"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0        1\n",
              "0                            i didnt feel humiliated  sadness\n",
              "1  i can go from feeling so hopeless to so damned...  sadness\n",
              "2   im grabbing a minute to post i feel greedy wrong    anger\n",
              "3  i am ever feeling nostalgic about the fireplac...     love\n",
              "4                               i am feeling grouchy    anger"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_9QzxEudsNZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "78b06189-69b4-4aa4-cdfb-5e87ce0bac6d"
      },
      "source": [
        "val.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im feeling quite sad and sorry for myself but ...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i feel like i am still looking at a blank canv...</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i feel like a faithful servant</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am just feeling cranky and blue</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i can have for a treat or if i am feeling festive</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0        1\n",
              "0  im feeling quite sad and sorry for myself but ...  sadness\n",
              "1  i feel like i am still looking at a blank canv...  sadness\n",
              "2                     i feel like a faithful servant     love\n",
              "3                  i am just feeling cranky and blue    anger\n",
              "4  i can have for a treat or if i am feeling festive      joy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm5oiPdBdzX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35664be5-0617-4ad5-d8a2-45ee9f55e528"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16000 entries, 0 to 15999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       16000 non-null  object\n",
            " 1   1       16000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 250.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65Vnk3FCd-kV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f527cdd-8084-4386-d087-402e727d59bf"
      },
      "source": [
        "test.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       2000 non-null   object\n",
            " 1   1       2000 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 31.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed_jdgjReCk1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa20570-d4ea-466e-b778-a86ccaa8493f"
      },
      "source": [
        "val.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2000 entries, 0 to 1999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   0       2000 non-null   object\n",
            " 1   1       2000 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 31.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZPo0O-emJ7q"
      },
      "source": [
        "# **Preparing the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDGvMyEZeDvH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed18d78d-1245-45a3-fd47-8b57546ba482"
      },
      "source": [
        "# Splitting X and Y\n",
        "x_train = train.iloc[:,0] \n",
        "y_train = train.iloc[:,1] \n",
        "\n",
        "x_test = test.iloc[:,0] \n",
        "y_test = test.iloc[:,1] \n",
        "\n",
        "x_val = test.iloc[:,0] \n",
        "y_val = test.iloc[:,1] \n",
        "\n",
        "x_train,y_train = np.array(x_train),np.array(y_train)\n",
        "x_test,y_test = np.array(x_test),np.array(y_test)\n",
        "x_val,y_val = np.array(x_val),np.array(y_val)\n",
        "\n",
        "print(x_train.shape,\"|\",y_train.shape)\n",
        "print(x_test.shape,\"|\",y_test.shape)\n",
        "print(x_val.shape,\"|\",y_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16000,) | (16000,)\n",
            "(2000,) | (2000,)\n",
            "(2000,) | (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-rurDLqeHSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8789d3e3-9128-470f-dfe5-cdc72988e75c"
      },
      "source": [
        "# Convert y to integers.\n",
        "print(train.iloc[:,1].value_counts())\n",
        "\n",
        "int_y_train = []\n",
        "int_y_test = []\n",
        "int_y_val = []\n",
        "\n",
        "for l in y_train:\n",
        "    \n",
        "    if l == \"joy\":        \n",
        "        int_y_train.append(0)   \n",
        "    if l == \"sadness\":       \n",
        "        int_y_train.append(1)            \n",
        "    if l == \"anger\":      \n",
        "        int_y_train.append(2)      \n",
        "    if l == \"fear\":\n",
        "        int_y_train.append(3)\n",
        "    if l == \"love\":\n",
        "        int_y_train.append(4)\n",
        "    if l == \"surprise\":\n",
        "        int_y_train.append(5)\n",
        "        \n",
        "        \n",
        "for l in y_test:\n",
        "    \n",
        "    if l == \"joy\":        \n",
        "        int_y_test.append(0)    \n",
        "    if l == \"sadness\":       \n",
        "        int_y_test.append(1)            \n",
        "    if l == \"anger\":      \n",
        "        int_y_test.append(2)      \n",
        "    if l == \"fear\":\n",
        "        int_y_test.append(3)\n",
        "    if l == \"love\":\n",
        "        int_y_test.append(4)\n",
        "    if l == \"surprise\":\n",
        "        int_y_test.append(5)\n",
        "        \n",
        "for l in y_val:\n",
        "    \n",
        "    if l == \"joy\":        \n",
        "        int_y_val.append(0)    \n",
        "    if l == \"sadness\":       \n",
        "        int_y_val.append(1)            \n",
        "    if l == \"anger\":      \n",
        "        int_y_val.append(2)      \n",
        "    if l == \"fear\":\n",
        "        int_y_val.append(3)\n",
        "    if l == \"love\":\n",
        "        int_y_val.append(4)\n",
        "    if l == \"surprise\":\n",
        "        int_y_val.append(5)\n",
        "\n",
        "int_y_train,int_y_test,int_y_val = np.array(int_y_train),np.array(int_y_test),np.array(int_y_val)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from keras.utils import np_utils\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(int_y_train)\n",
        "\n",
        "encoded_y_train = le.transform(int_y_train)\n",
        "encoded_y_test = le.transform(int_y_test)\n",
        "encoded_y_val = le.transform(int_y_val)\n",
        "\n",
        "encoded_y_train = np_utils.to_categorical(encoded_y_train)\n",
        "encoded_y_test = np_utils.to_categorical(encoded_y_test)\n",
        "encoded_y_val = np_utils.to_categorical(encoded_y_val)\n",
        "\n",
        "print(encoded_y_train)\n",
        "\n",
        "print(int_y_train[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "joy         5362\n",
            "sadness     4666\n",
            "anger       2159\n",
            "fear        1937\n",
            "love        1304\n",
            "surprise     572\n",
            "Name: 1, dtype: int64\n",
            "[[0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " ...\n",
            " [1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]]\n",
            "[1 1 2 4 2 1 5 3 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAajrt74fIAb"
      },
      "source": [
        "# **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv6NsELFetB-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4221d783-63c3-48f8-8d63-eb77c86c4a4c"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i didnt feel humiliated'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpL4UWe6fOOq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8dcd0812-37f6-4384-d8b8-fe280bccf28a"
      },
      "source": [
        "x_test[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'im updating my blog because i feel shitty'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR7PbJHZfOdk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9834bf29-6bea-43f9-9b54-bbfc1f048b94"
      },
      "source": [
        "x_val[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'im updating my blog because i feel shitty'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znRX-LBefPt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b7d5950-38fb-4fe9-8527-6536284756b0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDPQDtw3lJ23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f34074de-8323-4344-f470-c14360f56423"
      },
      "source": [
        "stopwords = stopwords.words('english')\n",
        "stopwords[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2M94ox-fS79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0dfb08-ce0f-4a7c-edf2-d16a60bc23a1"
      },
      "source": [
        "x_train_cl = []\n",
        "x_test_cl = []\n",
        "x_val_cl = []\n",
        "\n",
        "\n",
        "# Deleting stopwords\n",
        "for text in x_train:\n",
        "    \n",
        "    text = text.split()\n",
        "    text = [word for word in text if word not in stopwords]\n",
        "    text = \" \".join(text)\n",
        "    x_train_cl.append(text)\n",
        "\n",
        "for text in x_test:\n",
        "    \n",
        "    text = text.split()\n",
        "    text = [word for word in text if word not in stopwords]\n",
        "    text = \" \".join(text)\n",
        "    x_test_cl.append(text)\n",
        "\n",
        "for text in x_val:\n",
        "    \n",
        "    text = text.split()\n",
        "    text = [word for word in text if word not in stopwords]\n",
        "    text = \" \".join(text)\n",
        "    x_val_cl.append(text)\n",
        "    \n",
        "x_train,x_test,x_val = np.array(x_train_cl),np.array(x_test_cl),np.array(x_val_cl)\n",
        "\n",
        "# We use total_text for fitting tokenizer in general \n",
        "total_text = np.concatenate((x_train,x_test,x_val),axis=0)\n",
        "\n",
        "num_words = 2000\n",
        "\n",
        "tokenizer = Tokenizer(num_words = num_words) \n",
        "\n",
        "tokenizer.fit_on_texts(total_text)\n",
        "list(tokenizer.word_index)[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['feel',\n",
              " 'feeling',\n",
              " 'like',\n",
              " 'im',\n",
              " 'really',\n",
              " 'know',\n",
              " 'time',\n",
              " 'get',\n",
              " 'little',\n",
              " 'people']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huy8tyMufchD"
      },
      "source": [
        "# Tokenizing everything\n",
        "\n",
        "x_train_token = tokenizer.texts_to_sequences(x_train)\n",
        "x_test_token = tokenizer.texts_to_sequences(x_test)\n",
        "x_val_token = tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "total_token = np.concatenate((x_train_token,x_test_token,x_val_token),axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-Mrf3hNf1ue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc9c3e7c-4693-4eae-b98d-cccd731f8260"
      },
      "source": [
        "# Padding\n",
        "print(np.mean([len(text) for text in total_token]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.6699\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIfxVpmTf3uI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c20e1a40-b246-4def-8275-1a63192777f0"
      },
      "source": [
        "x_train_pad = pad_sequences(x_train_token,20) \n",
        "x_test_pad = pad_sequences(x_test_token,20)\n",
        "x_val_pad = pad_sequences(x_val_token,20)\n",
        "\n",
        "print(x_train_pad[0],end=\"\\n-------------------------------------------------------------------------\\n\")\n",
        "print(x_train_pad[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  50\n",
            "   1 495]\n",
            "-------------------------------------------------------------------------\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0   30    2\n",
            "  464  425   44   54 1573 1304]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxCs8ZmomaQv"
      },
      "source": [
        "# **Modeling and Predicting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4RvLx7Rf7Hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33edf670-0724-4e9d-f9ad-3d53c5ce908a"
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense,CuDNNGRU,Embedding,Bidirectional\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=2000\n",
        "                   ,output_dim=100\n",
        "                   ,input_length=20))\n",
        "\n",
        "model.add(Bidirectional(CuDNNGRU(units=16,return_sequences=True)))\n",
        "\n",
        "model.add(Bidirectional(CuDNNGRU(units=8)))\n",
        "\n",
        "model.add(Dense(6,activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"rmsprop\",metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 100)           200000    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 20, 32)            11328     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 16)                2016      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 102       \n",
            "=================================================================\n",
            "Total params: 213,446\n",
            "Trainable params: 213,446\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG1u6wekf_OV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c05e92d-8143-4097-8ea8-5bfe7e10879b"
      },
      "source": [
        "print(x_train_pad.shape)\n",
        "print(y_train.shape)\n",
        "model.fit(x_train_pad, encoded_y_train, epochs=10, batch_size=20) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(16000, 20)\n",
            "(16000,)\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 1.0392 - accuracy: 0.6116\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.3402 - accuracy: 0.8874\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.2067 - accuracy: 0.9216\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.1645 - accuracy: 0.9337\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.1417 - accuracy: 0.9414\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.1302 - accuracy: 0.9464\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.1207 - accuracy: 0.9506\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.1127 - accuracy: 0.9534\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 8s 9ms/step - loss: 0.1043 - accuracy: 0.9570\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 7s 9ms/step - loss: 0.0994 - accuracy: 0.9603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdf80155668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd7RZNR-gBOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4777f436-23be-4154-eb58-2d24ce7c49b4"
      },
      "source": [
        "preds = model.predict_classes(x_test_pad)\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-e0e3ac6ca3e6>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH_-OYIHj4lM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e1db45-72aa-4584-b50e-fa0958f993d0"
      },
      "source": [
        "accuracy_score(preds,int_y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9215"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZzKOF59CT3P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}